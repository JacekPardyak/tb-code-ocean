---
title: 'Data Science with Spark'
author: 'JG Pardyak'
date: '29-Sep-2022'
output: 
  ioslides_presentation:
    widescreen: true
    logo: logo.svg
    css: styles.css
---

```{r setup, include=FALSE}
library(tidyverse)
```

## <span>.</span>Outline

- Recap of the August meeting

- Data Science üíª

- Spark ‚ùáÔ∏è

- Data Science + Spark = ü•≥

- Code Surgery : Customer Segmentation


## <span>.</span>August meeting  {.columns-1}

Cluster analysis 

![](Capture-2022-08-25.PNG){width=65%}

## <span>.</span>Spark {.columns-2}

**Apache Spark** is an open-source unified analytics engine for large-scale data processing.

Initial release: 8 yo

Latest version: 3.3 

<p class="forceBreak"></p>

![](Apache_Spark_logo.svg)

## <span>.</span>Interacting with Spark from Python {.columns-1}

```{python, eval = FALSE}
from pyspark.sql import SparkSession
sc = SparkSession.builder.getOrCreate()
sqlContext.sql("show tables in jck").show()
```

```
+--------+--------------------+-----------+
|database|           tableName|isTemporary|
+--------+--------------------+-----------+
|     jck|            contract|      false|
|     jck|                iris|      false|
|     jck|   kaplanmeierfitter|      false|
|     jck|recommender_contract|      false|
|     jck|recommender_contr...|      false|
|     jck|    select_productid|      false|
|     jck|             tickets|      false|
+--------+--------------------+-----------+
```

##  <span>.</span>Interacting with Spark from R {.columns-1}

```{r, warning=FALSE, message=FALSE}
library(sparklyr)

sc <- spark_connect(master = Sys.getenv("master"), spark_home = Sys.getenv("spark_home")) 

connection_is_open(sc)

```

##  <span>.</span>K-Means Clustering in Spark {.columns-1}

```{r}
iris_tbl <- copy_to(sc, iris, "iris", overwrite = TRUE)

iris_tbl
```

##  <span>.</span>K-Means Clustering in Spark {.columns-1}

```{r}
kmeans_model <- iris_tbl %>%
  ml_kmeans(k = 3, features = c("Petal_Length", "Petal_Width"))

kmeans_model
```

##  <span>.</span>K-Means Clustering in Spark {.columns-1}

```{r}
predicted <- ml_predict(kmeans_model, iris_tbl) %>%
  collect()

table(predicted$Species, predicted$prediction)

```

##  <span>.</span>K-Means Clustering in Spark {.columns-2}

```{r, eval=FALSE}
predicted %>%
ggplot(aes(Petal_Length, Petal_Width)) +
geom_point(aes(Petal_Width, Petal_Length,
          col = factor(prediction + 1)),
size = 2, alpha = 0.5) +
geom_point(
data = kmeans_model$centers, 
aes(Petal_Width, Petal_Length),
col = scales::muted(
  c("red", "green", "blue")),
pch = "x", size = 12) +
scale_color_discrete(
name = "Predicted Cluster",
labels = paste("Cluster", 1:3)) +
labs(
x = "Petal Length",
y = "Petal Width")
```

<p class="forceBreak"></p>

```{r, echo=FALSE}
predicted %>%
  ggplot(aes(Petal_Length, Petal_Width)) +
  geom_point(aes(Petal_Width, Petal_Length, col = factor(prediction + 1)),
    size = 2, alpha = 0.5
  ) +
  geom_point(
    data = kmeans_model$centers, aes(Petal_Width, Petal_Length),
    col = scales::muted(c("red", "green", "blue")),
    pch = "x", size = 12
  ) +
  scale_color_discrete(
    name = "Predicted Cluster",
    labels = paste("Cluster", 1:3)
  ) +
  labs(
    x = "Petal Length",
    y = "Petal Width",
    title = "K-Means Clustering",
    subtitle = "Use Spark.ML to predict cluster membership with the iris dataset."
  )

```

##  <span>.</span>MLlib - Machine Learning algorithms in Spark {.columns-2}

- Spark ML - Regression

- Spark ML - Classification

- Spark ML - Tree

- Spark ML - Clustering

- Spark ML - Text

<p class="forceBreak"></p>

- Spark ML - Recommendations

- Spark ML - Hyper-parameter tuning

- Spark ML - Evaluation

- Spark ML - Operations

## <span>.</span>Code Surgery - Data Science with Spark

![](Capture-2022-09-29.PNG){width=65%}

