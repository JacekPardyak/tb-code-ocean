# -*- coding: utf-8 -*-
"""support-tickets-classification-R-TensorFlow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GEzdaRVRoqoIuUW5bqMJ3edFA2lu9BMW
"""

system("sudo lshw -C display", intern = TRUE)

system("ls ", intern = TRUE)

if(! require('keras')) install.packages('keras')
if(! require('yardstick')) install.packages('yardstick')
library(keras)

library(tensorflow)
tf$constant("Hello World")

library(tidyverse)
df <- read_csv("https://github.com/JacekPardyak/vps/raw/master/text-classification/all_tickets.csv.gz") %>%
  rename(text = body, tag = ticket_type)

head(df)

df %>% slice_sample()

df %>% count(tag)

df$text[1]

training_id <- sample.int(nrow(df), size = nrow(df)*0.8)
training <- df[training_id,]
testing <- df[-training_id,]

# distribution of the number of words in each review.
df$text %>% 
  strsplit(" ") %>% 
  sapply(length) %>% 
  summary()

num_words <- 1000
max_length <- 50
text_vectorization <- layer_text_vectorization(
  max_tokens = num_words, 
  output_sequence_length = max_length, 
)

# 'adapt' let layer learn about unique words in our dataset and assign an integer value for each one.
text_vectorization %>% 
  adapt(df$text)

get_vocabulary(text_vectorization)

text_vectorization(matrix(df$text[1], ncol = 1))

# build a model for this problem:
input <- layer_input(shape = c(1), dtype = "string")

output <- input %>% 
  text_vectorization() %>% 
  layer_embedding(input_dim = num_words + 1, output_dim = 16) %>%
  layer_global_average_pooling_1d() %>%
  layer_dense(units = 16, activation = "relu") %>%
  layer_dropout(0.5) %>% 
  layer_dense(units = 1, activation = "sigmoid")

model <- keras_model(input, output)

# configure the model to use an optimizer and a loss function:
model %>% compile(
  optimizer = 'adam',
  loss = 'binary_crossentropy',
  metrics = list('accuracy')
)

# train the model 
history <- model %>% fit(
  training$text,
  training$tag,
  epochs = 10,
  batch_size = 512,
  validation_split = 0.2,
  verbose=2
)

# evaluate the model
results <- model %>% evaluate(testing$text, testing$tag, verbose = 0)
results

plot(history)

library(yardstick)
classifications <- testing %>% cbind(probability = model %>% 
  predict(testing$text)) %>%
  mutate(tag = factor(tag))
#predict(model, new_data = testing$text, type = "prob")
#cbind(predict(model, new_data = testing, type = "prob"))

classifications %>%
  roc_curve(tag,  probability, event_level = "second") %>% autoplot()

classifications %>%
  roc_auc(tag,  probability, event_level = "second")

# deployment
sample <- df %>% slice_sample()
sample$tag; sample$text 
model %>% predict(sample$text)

"""# References
- https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_basic_text_classification/
- https://tensorflow.rstudio.com/installation/gpu/

"""